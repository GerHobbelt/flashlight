{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arrayfire as af\n",
    "import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toArrayFire(x):\n",
    "    x_np = x.detach().contiguous().numpy()\n",
    "    shape = 1\n",
    "    if len(x_np.shape) == 0:\n",
    "        shape = (1,)\n",
    "    else:\n",
    "        shape = x_np.shape[::-1]\n",
    "    afArray = af.Array(x_np.ctypes.data, shape, x_np.dtype.char)\n",
    "    return afArray\n",
    "\n",
    "def saveStateDict(module, filepath):\n",
    "    i = 0\n",
    "    for (name, param) in module.named_parameters():\n",
    "        #param = module.state_dict()[name]\n",
    "        print(name, \"\\t\", param.size())\n",
    "        if 'in_proj' in name:\n",
    "            print(param.shape)\n",
    "            q, k, v = param.chunk(3, dim=0)\n",
    "            print('in_proj!')\n",
    "            af.array.save_array(name + 'q', toArrayFire(q), filepath, True)\n",
    "            af.array.save_array(name + 'k', toArrayFire(k), filepath, True)\n",
    "            af.array.save_array(name + 'v', toArrayFire(k), filepath, True)\n",
    "            continue\n",
    "        if len(param.size()) > 0:\n",
    "            af_array = toArrayFire(param)\n",
    "            if 'fc' in name and 'weight' in name:\n",
    "                af_array = af.array.transpose(af_array)\n",
    "            af.array.save_array(name, af_array, filepath, True)\n",
    "            i = i + 1\n",
    "    print(i)\n",
    "    for name in module.state_dict():\n",
    "        if 'running' in name:\n",
    "            print(name)\n",
    "            af_array = toArrayFire(module.state_dict()[name])\n",
    "            af.array.save_array(name, af_array, filepath + 'running', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.backbone import *\n",
    "from models.position_encoding import *\n",
    "from models.matcher import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.transformer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "embedding_size = 128\n",
    "src_len = 5\n",
    "tgt_len = 10\n",
    "num_layers = 2\n",
    "queries = torch.rand(tgt_len, batch_size, embedding_size)\n",
    "memory = torch.rand(src_len, batch_size, embedding_size)\n",
    "layer = TransformerDecoderLayer(embedding_size, 1, dropout=0.0, dim_feedforward=128)\n",
    "norm = nn.LayerNorm(embedding_size)\n",
    "model = TransformerDecoder(layer, num_layers, return_intermediate=True, norm=norm)\n",
    "output = model.forward(queries, memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0q_0layers.0.self_attn.in_proj_weight 2 torch.Size([128, 128])\n",
      "2\n",
      "0q_1layers.0.self_attn.in_proj_bias 3 torch.Size([128])\n",
      "3\n",
      "1k_0layers.0.self_attn.in_proj_weight 4 torch.Size([128, 128])\n",
      "4\n",
      "1k_1layers.0.self_attn.in_proj_bias 5 torch.Size([128])\n",
      "5\n",
      "2v_0layers.0.self_attn.in_proj_weight 6 torch.Size([128, 128])\n",
      "6\n",
      "2v_1layers.0.self_attn.in_proj_bias 7 torch.Size([128])\n",
      "7\n",
      "layers.0.self_attn.out_proj.weight 8 torch.Size([128, 128])\n",
      "8\n",
      "layers.0.self_attn.out_proj.bias 9 torch.Size([128])\n",
      "9\n",
      "0q_0layers.0.multihead_attn.in_proj_weight 10 torch.Size([128, 128])\n",
      "10\n",
      "0q_1layers.0.multihead_attn.in_proj_bias 11 torch.Size([128])\n",
      "11\n",
      "1k_0layers.0.multihead_attn.in_proj_weight 12 torch.Size([128, 128])\n",
      "12\n",
      "1k_1layers.0.multihead_attn.in_proj_bias 13 torch.Size([128])\n",
      "13\n",
      "2v_0layers.0.multihead_attn.in_proj_weight 14 torch.Size([128, 128])\n",
      "14\n",
      "2v_1layers.0.multihead_attn.in_proj_bias 15 torch.Size([128])\n",
      "15\n",
      "layers.0.multihead_attn.out_proj.weight 16 torch.Size([128, 128])\n",
      "16\n",
      "layers.0.multihead_attn.out_proj.bias 17 torch.Size([128])\n",
      "17\n",
      "layers.0.linear1.weight 18 torch.Size([128, 128])\n",
      "18\n",
      "layers.0.linear1.bias 19 torch.Size([128])\n",
      "19\n",
      "layers.0.linear2.weight 20 torch.Size([128, 128])\n",
      "20\n",
      "layers.0.linear2.bias 21 torch.Size([128])\n",
      "21\n",
      "layers.0.norm1.weight 22 torch.Size([128])\n",
      "22\n",
      "layers.0.norm1.bias 23 torch.Size([128])\n",
      "23\n",
      "layers.0.norm2.weight 24 torch.Size([128])\n",
      "24\n",
      "layers.0.norm2.bias 25 torch.Size([128])\n",
      "25\n",
      "layers.0.norm3.weight 26 torch.Size([128])\n",
      "26\n",
      "layers.0.norm3.bias 27 torch.Size([128])\n",
      "27\n",
      "0q_0layers.1.self_attn.in_proj_weight 28 torch.Size([128, 128])\n",
      "28\n",
      "0q_1layers.1.self_attn.in_proj_bias 29 torch.Size([128])\n",
      "29\n",
      "1k_0layers.1.self_attn.in_proj_weight 30 torch.Size([128, 128])\n",
      "30\n",
      "1k_1layers.1.self_attn.in_proj_bias 31 torch.Size([128])\n",
      "31\n",
      "2v_0layers.1.self_attn.in_proj_weight 32 torch.Size([128, 128])\n",
      "32\n",
      "2v_1layers.1.self_attn.in_proj_bias 33 torch.Size([128])\n",
      "33\n",
      "layers.1.self_attn.out_proj.weight 34 torch.Size([128, 128])\n",
      "34\n",
      "layers.1.self_attn.out_proj.bias 35 torch.Size([128])\n",
      "35\n",
      "0q_0layers.1.multihead_attn.in_proj_weight 36 torch.Size([128, 128])\n",
      "36\n",
      "0q_1layers.1.multihead_attn.in_proj_bias 37 torch.Size([128])\n",
      "37\n",
      "1k_0layers.1.multihead_attn.in_proj_weight 38 torch.Size([128, 128])\n",
      "38\n",
      "1k_1layers.1.multihead_attn.in_proj_bias 39 torch.Size([128])\n",
      "39\n",
      "2v_0layers.1.multihead_attn.in_proj_weight 40 torch.Size([128, 128])\n",
      "40\n",
      "2v_1layers.1.multihead_attn.in_proj_bias 41 torch.Size([128])\n",
      "41\n",
      "layers.1.multihead_attn.out_proj.weight 42 torch.Size([128, 128])\n",
      "42\n",
      "layers.1.multihead_attn.out_proj.bias 43 torch.Size([128])\n",
      "43\n",
      "layers.1.linear1.weight 44 torch.Size([128, 128])\n",
      "44\n",
      "layers.1.linear1.bias 45 torch.Size([128])\n",
      "45\n",
      "layers.1.linear2.weight 46 torch.Size([128, 128])\n",
      "46\n",
      "layers.1.linear2.bias 47 torch.Size([128])\n",
      "47\n",
      "layers.1.norm1.weight 48 torch.Size([128])\n",
      "48\n",
      "layers.1.norm1.bias 49 torch.Size([128])\n",
      "49\n",
      "layers.1.norm2.weight 50 torch.Size([128])\n",
      "50\n",
      "layers.1.norm2.bias 51 torch.Size([128])\n",
      "51\n",
      "layers.1.norm3.weight 52 torch.Size([128])\n",
      "52\n",
      "layers.1.norm3.bias 53 torch.Size([128])\n",
      "53\n",
      "norm.weight 54 torch.Size([128])\n",
      "54\n",
      "norm.bias 55 torch.Size([128])\n",
      "55\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = '/private/home/padentomasello/scratch/pytorch_testing/transformer_decoder.array'\n",
    "af.array.save_array('queries', toArrayFire(queries), filepath, False)\n",
    "af.array.save_array('memory', toArrayFire(memory), filepath, True)\n",
    "i = 2\n",
    "params = {}\n",
    "for (name, param) in model.named_parameters():\n",
    "        if 'in_proj' in name:\n",
    "            q, k, v = param.chunk(3, dim=0)\n",
    "            hack = '0'\n",
    "            if 'in_proj_bias' in name: hack = '1'\n",
    "            params['0q_' + hack + name] = q\n",
    "            params['1k_' + hack + name] = k\n",
    "            params['2v_' + hack + name] = v\n",
    "            if 'in_proj_bias' in name:\n",
    "                for key in sorted(params.keys()):\n",
    "                    af_array = toArrayFire(params[key])\n",
    "                    if 'weight' in key:\n",
    "                        af_array = af.array.transpose(af_array)\n",
    "                    print(key, i, params[key].shape)\n",
    "                    print(af.array.save_array(key, af_array, filepath, True))\n",
    "                    i = i + 1\n",
    "                params = {}\n",
    "            continue\n",
    "        elif len(param.size()) > 0:\n",
    "            af_array = toArrayFire(param)\n",
    "            if 'fc' in name and 'weight' in name:\n",
    "                af_array = af.array.transpose(af_array)\n",
    "            if 'weight' in name and 'proj' in name:\n",
    "                af_array = af.array.transpose(af_array)\n",
    "            if 'weight' in name and 'linear' in name:\n",
    "                af_array = af.array.transpose(af_array)\n",
    "            print(name, i, param.shape)\n",
    "            print(af.array.save_array(name, af_array, filepath, True))\n",
    "            i = i + 1\n",
    "#af.array.save_array('output', toArrayFire(output), filepath, True)\n",
    "af.array.save_array('output', toArrayFire(output), filepath, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 1, 128])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
