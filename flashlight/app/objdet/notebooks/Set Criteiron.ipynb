{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arrayfire as af\n",
    "import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toArrayFire(x):\n",
    "    x_np = x.detach().contiguous().numpy()\n",
    "    shape = 1\n",
    "    if len(x_np.shape) == 0:\n",
    "        shape = (1,)\n",
    "    else:\n",
    "        shape = x_np.shape[::-1]\n",
    "    print(shape)\n",
    "    afArray = af.Array(x_np.ctypes.data, shape, x_np.dtype.char)\n",
    "    return afArray\n",
    "\n",
    "def saveStateDict(module, filepath):\n",
    "    i = 0\n",
    "    for (name, param) in module.named_parameters():\n",
    "        #param = module.state_dict()[name]\n",
    "        print(name, \"\\t\", param.size())\n",
    "        if 'in_proj' in name:\n",
    "            print(param.shape)\n",
    "            q, k, v = param.chunk(3, dim=0)\n",
    "            print('in_proj!')\n",
    "            af.array.save_array(name + 'q', toArrayFire(q), filepath, True)\n",
    "            af.array.save_array(name + 'k', toArrayFire(k), filepath, True)\n",
    "            af.array.save_array(name + 'v', toArrayFire(k), filepath, True)\n",
    "            continue\n",
    "        if len(param.size()) > 0:\n",
    "            af_array = toArrayFire(param)\n",
    "            if 'fc' in name and 'weight' in name:\n",
    "                af_array = af.array.transpose(af_array)\n",
    "            af.array.save_array(name, af_array, filepath, True)\n",
    "            i = i + 1\n",
    "    print(i)\n",
    "    for name in module.state_dict():\n",
    "        if 'running' in name:\n",
    "            print(name)\n",
    "            af_array = toArrayFire(module.state_dict()[name])\n",
    "            af.array.save_array(name, af_array, filepath + 'running', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 2)\n",
      "torch.Size([7, 5])\n",
      "weight \t torch.Size([7, 5])\n",
      "(5, 7)\n",
      "1\n",
      "(7, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = '/private/home/padentomasello/scratch/pytorch_testing/basic_linear.array'\n",
    "batchSize = 2\n",
    "inChannels = 5\n",
    "outChannels = 7\n",
    "\n",
    "x = torch.rand(batchSize, inChannels)\n",
    "x_af = toArrayFire(x)\n",
    "\n",
    "af.array.save_array('input', x_af, filepath)\n",
    "model = torch.nn.Linear(inChannels, outChannels, False)\n",
    "weight = torch.stack([torch.arange(0, inChannels, dtype=torch.float32) for i in range(outChannels)], 0)\n",
    "print(weight.shape)\n",
    "model.weight = torch.nn.Parameter(weight)\n",
    "output = model(x)\n",
    "saveStateDict(model, filepath)\n",
    "af.array.save_array('output', toArrayFire(output), filepath, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.2556, 7.2556, 7.2556, 7.2556, 7.2556, 7.2556, 7.2556],\n",
       "        [3.5327, 3.5327, 3.5327, 3.5327, 3.5327, 3.5327, 3.5327]],\n",
       "       grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92, 20, 2)\n",
      "(4, 20, 2)\n",
      "(4, 3)\n",
      "(4, 12)\n",
      "(3,)\n",
      "(12,)\n"
     ]
    }
   ],
   "source": [
    "from models.detr import *\n",
    "from models.matcher import *\n",
    "class NestedTensor(object):\n",
    "\n",
    "    def __init__(self, mask):\n",
    "        self.mask = mask\n",
    "        self.tensors = torch.ones(1)\n",
    "\n",
    "filepath = '/private/home/padentomasello/scratch/pytorch_testing/matcher.array'\n",
    "\n",
    "matcher = HungarianMatcher(1, 1, 1)\n",
    "batch_size = 2\n",
    "num_queries = 20\n",
    "num_classes = 91\n",
    "\n",
    "pred_logits = torch.rand(batch_size, num_queries, num_classes + 1, requires_grad=True)\n",
    "pred_boxes = torch.rand(batch_size, num_queries, 4, requires_grad=True)\n",
    "outputs = {\n",
    "    \"pred_logits\":pred_logits,\n",
    "    \"pred_boxes\":pred_boxes\n",
    "}\n",
    "\n",
    "targets = [\n",
    "{'boxes': torch.tensor([[0.4395, 0.3252, 0.0628, 0.1583],\n",
    "        [0.4474, 0.3120, 0.3526, 0.4358],\n",
    "        [0.5994, 0.0650, 0.2941, 0.1118]]),\n",
    " 'labels': torch.tensor([32,  1, 85]),\n",
    "},\n",
    " {'boxes': torch.tensor([[0.6240, 0.2875, 0.1698, 0.3400],\n",
    "        [0.2351, 0.5314, 0.4701, 0.9371],\n",
    "        [0.4722, 0.6277, 0.2816, 0.7445],\n",
    "        [0.7453, 0.5528, 0.5094, 0.8945],\n",
    "        [0.6128, 0.6995, 0.1498, 0.0647],\n",
    "        [0.4731, 0.4819, 0.1561, 0.0233],\n",
    "        [0.9721, 0.2031, 0.0187, 0.1447],\n",
    "        [0.9882, 0.1968, 0.0236, 0.1408],\n",
    "        [0.9960, 0.6344, 0.0080, 0.4890],\n",
    "        [0.1050, 0.2647, 0.2100, 0.4400],\n",
    "        [0.9948, 0.4351, 0.0104, 0.0984],\n",
    "        [0.9401, 0.1980, 0.0253, 0.1481]]), \n",
    "  'labels': torch.tensor([ 1,  1,  1,  1, 51, 48, 50, 50, 79,  1, 51, 50])\n",
    " }\n",
    "]\n",
    "#targets = [\n",
    "#{'boxes': torch.tensor([[0.4395, 0.3252, 0.0628, 0.1583],\n",
    "#        [0.4474, 0.3120, 0.3526, 0.4358],\n",
    "#        [0.5994, 0.0650, 0.2941, 0.1118]]),\n",
    "# 'labels': torch.tensor([0,  1, 1]),}\n",
    "#]\n",
    "\n",
    "base_filepath = '/private/home/padentomasello/scratch/pytorch_testing/matcher_test0'\n",
    "bbox_filepath = base_filepath + '_bboxes.array'\n",
    "label_filepath = base_filepath + '_labels.array'\n",
    "af.array.save_array('pred_logits', toArrayFire(pred_logits), base_filepath + 'input.array')\n",
    "af.array.save_array('pred_boxes', toArrayFire(pred_boxes), base_filepath + 'input.array', True)\n",
    "bboxes = [ toArrayFire(target[\"boxes\"]) for target in targets ]\n",
    "labels = [ toArrayFire(target[\"labels\"]) for target in targets ]\n",
    "for box in bboxes:\n",
    "    af.array.save_array('boxes', box, bbox_filepath, True)\n",
    "    \n",
    "for label in labels:\n",
    "    af.array.save_array('label', label, label_filepath, True)\n",
    "\n",
    "\n",
    "result = matcher.forward(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92, 20, 2)\n",
      "0\n",
      "(4, 20, 2)\n",
      "1\n",
      "(4, 3)\n",
      "(4, 12)\n",
      "(3,)\n",
      "(12,)\n",
      "here2 0\n",
      "here2 1\n",
      "here 0\n",
      "here 1\n",
      "[(tensor([0, 6, 7]), tensor([2, 1, 0])), (tensor([ 0,  2,  5,  6,  8, 11, 12, 14, 15, 16, 17, 19]), tensor([10,  2,  5,  7,  8,  3,  1, 11,  6,  0,  4,  9]))]\n",
      "here\n",
      "tensor([[85, 91, 91, 91, 91, 91,  1, 32, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91,\n",
      "         91, 91],\n",
      "        [51, 91,  1, 91, 91, 48, 50, 91, 79, 91, 91,  1,  1, 91, 50, 50,  1, 51,\n",
      "         91,  1]])\n",
      "tensor([[[0.8771, 0.3445, 0.7739,  ..., 0.1834, 0.6261, 0.7407],\n",
      "         [0.8994, 0.7917, 0.7706,  ..., 0.2017, 0.0570, 0.4281],\n",
      "         [0.6708, 0.4379, 0.3421,  ..., 0.4119, 0.7743, 0.7403],\n",
      "         ...,\n",
      "         [0.6878, 0.7168, 0.9990,  ..., 0.7257, 0.3486, 0.8485],\n",
      "         [0.2410, 0.3199, 0.8637,  ..., 0.7191, 0.5703, 0.7800],\n",
      "         [0.6612, 0.8621, 0.5733,  ..., 0.4579, 0.3235, 0.5163]],\n",
      "\n",
      "        [[0.3773, 0.9716, 0.1230,  ..., 0.0232, 0.1671, 0.3842],\n",
      "         [0.1942, 0.9531, 0.5105,  ..., 0.5641, 0.0799, 0.9404],\n",
      "         [0.7644, 0.6887, 0.2600,  ..., 0.1486, 0.2240, 0.5077],\n",
      "         ...,\n",
      "         [0.3047, 0.4064, 0.8098,  ..., 0.9311, 0.7921, 0.6641],\n",
      "         [0.2198, 0.7727, 0.3334,  ..., 0.7933, 0.2823, 0.3968],\n",
      "         [0.1945, 0.4681, 0.1649,  ..., 0.0585, 0.6167, 0.6901]]],\n",
      "       requires_grad=True)\n",
      "> \u001b[0;32m/private/home/padentomasello/code/detection-transformer/models/detr.py\u001b[0m(116)\u001b[0;36mloss_labels\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    114 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    115 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 116 \u001b[0;31m        \u001b[0mloss_ce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    117 \u001b[0;31m        \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'loss_ce'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss_ce\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    118 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> \n",
      "ipdb> c\n",
      "{'loss_bbox': tensor(0.7631, grad_fn=<DivBackward0>), 'loss_giou': tensor(1.0917, grad_fn=<DivBackward0>), 'cardinality_error': tensor(12.), 'loss_ce': tensor(4.4524, grad_fn=<NllLoss2DBackward>), 'class_error': tensor(100.)}\n",
      "(1,)\n",
      "loss_bbox 0\n",
      "(1,)\n",
      "loss_giou 1\n",
      "(1,)\n",
      "cardinality_error 2\n",
      "(1,)\n",
      "loss_ce 3\n",
      "(1,)\n",
      "class_error 4\n"
     ]
    }
   ],
   "source": [
    "from models.detr import *\n",
    "base_filepath = '/private/home/padentomasello/scratch/pytorch_testing/set_criterion'\n",
    "bbox_filepath = base_filepath + '_bboxes.array'\n",
    "label_filepath = base_filepath + '_labels.array'\n",
    "loss_filepath = base_filepath + '_loss.array'\n",
    "grad_filepath = base_filepath + '_grad.array'\n",
    "pred_logits.grad = None\n",
    "pred_boxes.grad = None\n",
    "print(af.array.save_array('pred_logits', toArrayFire(pred_logits), base_filepath + '_input.array', False))\n",
    "print(af.array.save_array('pred_boxes', toArrayFire(pred_boxes), base_filepath + '_input.array', True))\n",
    "bboxes = [ toArrayFire(target[\"boxes\"]) for target in targets ]\n",
    "labels = [ toArrayFire(target[\"labels\"]) for target in targets ]\n",
    "append = False\n",
    "for box in bboxes:\n",
    "    print('here2', af.array.save_array('boxes', box, bbox_filepath, append))\n",
    "    append = True\n",
    "append = False    \n",
    "for label in labels:\n",
    "    print('here', af.array.save_array('label', label, label_filepath, append))\n",
    "    append = True\n",
    "\n",
    "\n",
    "result = matcher.forward(outputs, targets)\n",
    "weight_dict = {'loss_ce': 1, 'loss_bbox': 1}\n",
    "weight_dict['loss_giou'] = 1\n",
    "losses = []\n",
    "losses.extend(['boxes', 'cardinality'])\n",
    "losses.append('labels')\n",
    "eos_coef = 0.1\n",
    "crit = SetCriterion(num_classes, matcher, weight_dict, eos_coef, losses)\n",
    "append = False\n",
    "losses = crit.forward(outputs, targets)\n",
    "for key, array in losses.items():\n",
    "    print(key, af.array.save_array(key + '_0', toArrayFire(array), loss_filepath, append))\n",
    "    #array.backward(retain_graph=True)\n",
    "    append = True\n",
    "losses['loss_bbox'].backward(retain_graph=True)\n",
    "losses['loss_giou'].backward(retain_graph=True)\n",
    "losses['loss_ce'].backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2190, -0.0667,  0.0057,  0.1792],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.1743,  0.1556,  0.0147,  0.0534],\n",
      "         [ 0.1074, -0.0667,  0.0208, -0.1948],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0667, -0.0667,  0.0668,  0.0668],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.2820,  0.1457, -0.0793, -0.0826],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.1596,  0.0667,  0.0014,  0.0679],\n",
      "         [-0.0667, -0.1010,  0.0766, -0.5111],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.0667,  0.1423,  0.0698,  0.0182],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0667,  0.1238,  0.0919,  0.0460],\n",
      "         [-0.0667, -0.1616,  0.1165, -0.0752],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.1435,  0.3219,  0.0272, -0.0568],\n",
      "         [-0.0667, -0.1640,  0.0737, -0.0699],\n",
      "         [ 0.0667,  0.0667,  0.1324,  0.1053],\n",
      "         [ 0.2190,  0.0667, -0.0540,  0.0718],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.2908,  0.0667, -0.1555,  0.1245]]])\n",
      "tensor([[[ 8.7721e-04,  5.1499e-04,  7.9120e-04,  ...,  4.3839e-04,\n",
      "           6.8251e-04,  7.6539e-04],\n",
      "         [ 9.0268e-05,  8.1056e-05,  7.9362e-05,  ...,  4.4929e-05,\n",
      "           3.8876e-05, -5.6579e-03],\n",
      "         [ 6.8558e-05,  5.4315e-05,  4.9354e-05,  ...,  5.2924e-05,\n",
      "           7.6037e-05, -5.6408e-03],\n",
      "         ...,\n",
      "         [ 7.2906e-05,  7.5051e-05,  9.9528e-05,  ...,  7.5722e-05,\n",
      "           5.1933e-05, -5.6287e-03],\n",
      "         [ 4.4776e-05,  4.8455e-05,  8.3466e-05,  ...,  7.2231e-05,\n",
      "           6.2243e-05, -5.6375e-03],\n",
      "         [ 7.1208e-05,  8.7048e-05,  6.5215e-05,  ...,  5.8110e-05,\n",
      "           5.0802e-05, -5.6527e-03]],\n",
      "\n",
      "        [[ 5.3458e-04,  9.6862e-04,  4.1458e-04,  ...,  3.7517e-04,\n",
      "           4.3323e-04,  5.3829e-04],\n",
      "         [ 4.3240e-05,  9.2354e-05,  5.9327e-05,  ...,  6.2592e-05,\n",
      "           3.8568e-05, -5.6231e-03],\n",
      "         [ 8.1036e-04, -5.6392e-02,  4.8934e-04,  ...,  4.3776e-04,\n",
      "           4.7206e-04,  6.2689e-04],\n",
      "         ...,\n",
      "         [ 4.8535e-04,  5.3731e-04,  8.0430e-04,  ...,  9.0803e-04,\n",
      "           7.9021e-04,  6.9526e-04],\n",
      "         [ 4.5788e-05,  7.9600e-05,  5.1301e-05,  ...,  8.1252e-05,\n",
      "           4.8742e-05, -5.6596e-03],\n",
      "         [ 4.4665e-04, -5.6556e-02,  4.3362e-04,  ...,  3.8988e-04,\n",
      "           6.8132e-04,  7.3315e-04]]])\n",
      "(4, 20, 2)\n",
      "0\n",
      "(92, 20, 2)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(outputs[\"pred_boxes\"].grad)\n",
    "print(outputs[\"pred_logits\"].grad)\n",
    "print(af.array.save_array('pred_boxes', toArrayFire(outputs[\"pred_boxes\"].grad), grad_filepath, False))\n",
    "print(af.array.save_array('pred_logits', toArrayFire(outputs[\"pred_logits\"].grad), grad_filepath, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/private/home/padentomasello/scratch/pytorch_testing/set_criterion_loss.array'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "(2,)\n",
      "(3,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.7808, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = '/private/home/padentomasello/scratch/pytorch_testing/weight_cross_entropy.array'\n",
    "\n",
    "num_classes = 2\n",
    "weights = torch.ones(num_classes)\n",
    "weights[0:1] = 0.1\n",
    "input = torch.randn(3, num_classes, requires_grad=True)\n",
    "target = torch.randint(num_classes, (3,), dtype=torch.int64)\n",
    "af.array.save_array('input', toArrayFire(input), filepath, False)\n",
    "af.array.save_array('weight', toArrayFire(weights), filepath, True)\n",
    "af.array.save_array('target', toArrayFire(target), filepath, True)\n",
    "F.cross_entropy(input, target, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmaxed = torch.nn.functional.log_softmax(input, 1)\n",
    "loss = torch.nn.functional.nll_loss(softmaxed, target, weights, None, -1, None, 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0511,  0.0511],\n",
       "        [ 0.7241, -0.7241],\n",
       "        [-0.0077,  0.0077]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9484, -0.4900],\n",
       "        [-0.1404, -2.0324],\n",
       "        [-0.0971, -2.3803]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmaxed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0948, 2.0324, 0.0097], grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.nll_loss(softmaxed, target, weights, None, -1, None, 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7808, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.nll_loss(softmaxed, target, weights, None, -1, None, 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.1369, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.nll_loss(softmaxed, target, weights, None, -1, None, 'sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9484, 2.0324, 0.0971], grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.nll_loss(softmaxed, target, None, None, -1, None, 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.0779, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.nll_loss(softmaxed, target, None, None, -1, None, 'sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0260, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.nll_loss(softmaxed, target, None, None, -1, None, 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
