{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arrayfire as af\n",
    "import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toArrayFire(x):\n",
    "    x_np = x.detach().contiguous().numpy()\n",
    "    shape = 1\n",
    "    if len(x_np.shape) == 0:\n",
    "        shape = (1,)\n",
    "    else:\n",
    "        shape = x_np.shape[::-1]\n",
    "    afArray = af.Array(x_np.ctypes.data, shape, x_np.dtype.char)\n",
    "    return afArray\n",
    "\n",
    "def saveStateDict(module, filepath):\n",
    "    i = 0\n",
    "    for (name, param) in module.named_parameters():\n",
    "        #param = module.state_dict()[name]\n",
    "        print(name, \"\\t\", param.size())\n",
    "        if 'in_proj' in name:\n",
    "            print(param.shape)\n",
    "            q, k, v = param.chunk(3, dim=0)\n",
    "            print('in_proj!')\n",
    "            af.array.save_array(name + 'q', toArrayFire(q), filepath, True)\n",
    "            af.array.save_array(name + 'k', toArrayFire(k), filepath, True)\n",
    "            af.array.save_array(name + 'v', toArrayFire(k), filepath, True)\n",
    "            continue\n",
    "        if len(param.size()) > 0:\n",
    "            af_array = toArrayFire(param)\n",
    "            if 'fc' in name and 'weight' in name:\n",
    "                af_array = af.array.transpose(af_array)\n",
    "            af.array.save_array(name, af_array, filepath, True)\n",
    "            i = i + 1\n",
    "    print(i)\n",
    "    for name in module.state_dict():\n",
    "        if 'running' in name:\n",
    "            print(name)\n",
    "            af_array = toArrayFire(module.state_dict()[name])\n",
    "            af.array.save_array(name, af_array, filepath + 'running', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.backbone import *\n",
    "from models.position_encoding import *\n",
    "from models.matcher import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.transformer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0490,  0.0873,  0.3679,  0.2326, -0.3538,  0.4081, -0.4808,\n",
      "          -0.0980, -0.2038, -0.0947,  0.3269, -0.0382]],\n",
      "\n",
      "        [[ 0.0479,  0.0888,  0.3667,  0.2319, -0.3535,  0.4089, -0.4807,\n",
      "          -0.0980, -0.2073, -0.0962,  0.3247, -0.0381]],\n",
      "\n",
      "        [[ 0.0478,  0.0899,  0.3655,  0.2316, -0.3535,  0.4091, -0.4792,\n",
      "          -0.0987, -0.2110, -0.0977,  0.3198, -0.0385]],\n",
      "\n",
      "        [[ 0.0486,  0.0893,  0.3671,  0.2326, -0.3523,  0.4077, -0.4804,\n",
      "          -0.0984, -0.2056, -0.0970,  0.3229, -0.0399]],\n",
      "\n",
      "        [[ 0.0478,  0.0899,  0.3664,  0.2310, -0.3533,  0.4095, -0.4801,\n",
      "          -0.0990, -0.2121, -0.0979,  0.3207, -0.0383]],\n",
      "\n",
      "        [[ 0.0484,  0.0892,  0.3672,  0.2315, -0.3535,  0.4095, -0.4806,\n",
      "          -0.0987, -0.2113, -0.0977,  0.3225, -0.0384]],\n",
      "\n",
      "        [[ 0.0491,  0.0873,  0.3678,  0.2329, -0.3536,  0.4079, -0.4805,\n",
      "          -0.0978, -0.2030, -0.0947,  0.3267, -0.0386]],\n",
      "\n",
      "        [[ 0.0481,  0.0894,  0.3669,  0.2322, -0.3536,  0.4092, -0.4812,\n",
      "          -0.0982, -0.2102, -0.0980,  0.3233, -0.0387]],\n",
      "\n",
      "        [[ 0.0496,  0.0888,  0.3693,  0.2325, -0.3526,  0.4085, -0.4820,\n",
      "          -0.0986, -0.2078, -0.0978,  0.3248, -0.0401]],\n",
      "\n",
      "        [[ 0.0487,  0.0872,  0.3680,  0.2322, -0.3538,  0.4083, -0.4811,\n",
      "          -0.0982, -0.2045, -0.0945,  0.3273, -0.0376]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "embedding_size = 12\n",
    "src_len = 5\n",
    "tgt_len = 10\n",
    "queries = torch.rand(tgt_len, batch_size, embedding_size)\n",
    "memory = torch.rand(src_len, batch_size, embedding_size)\n",
    "model = TransformerDecoderLayer(embedding_size, 1, dropout=0.0, dim_feedforward=128)\n",
    "output = model.forward(queries, memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0q_0in_proj_weight 2 torch.Size([128, 128])\n",
      "2\n",
      "0q_1in_proj_bias 3 torch.Size([128])\n",
      "3\n",
      "1k_0in_proj_weight 4 torch.Size([128, 128])\n",
      "4\n",
      "1k_1in_proj_bias 5 torch.Size([128])\n",
      "5\n",
      "2v_0in_proj_weight 6 torch.Size([128, 128])\n",
      "6\n",
      "2v_1in_proj_bias 7 torch.Size([128])\n",
      "7\n",
      "out_proj.weight 8 torch.Size([128, 128])\n",
      "8\n",
      "out_proj.bias 9 torch.Size([128])\n",
      "9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = '/private/home/padentomasello/scratch/pytorch_testing/transformer_decoder_layer.array'\n",
    "af.array.save_array('queries', toArrayFire(queries), filepath, False)\n",
    "af.array.save_array('memory', toArrayFire(memory), filepath, True)\n",
    "i = 2\n",
    "params = {}\n",
    "for (name, param) in model.named_parameters():\n",
    "        if 'in_proj' in name:\n",
    "            q, k, v = param.chunk(3, dim=0)\n",
    "            hack = '0'\n",
    "            if 'in_proj_bias' in name: hack = '1'\n",
    "            params['0q_' + hack + name] = q\n",
    "            params['1k_' + hack + name] = k\n",
    "            params['2v_' + hack + name] = v\n",
    "            if 'in_proj_bias' in name:\n",
    "                for key in sorted(params.keys()):\n",
    "                    af_array = toArrayFire(params[key])\n",
    "                    if 'weight' in key:\n",
    "                        af_array = af.array.transpose(af_array)\n",
    "                    print(key, i, params[key].shape)\n",
    "                    print(af.array.save_array(key, af_array, filepath, True))\n",
    "                    i = i + 1\n",
    "                params = {}\n",
    "            continue\n",
    "        elif len(param.size()) > 0:\n",
    "            af_array = toArrayFire(param)\n",
    "            if 'fc' in name and 'weight' in name:\n",
    "                af_array = af.array.transpose(af_array)\n",
    "            if 'weight' in name and 'proj' in name:\n",
    "                af_array = af.array.transpose(af_array)\n",
    "            if 'weight' in name and 'linear' in name:\n",
    "                af_array = af.array.transpose(af_array)\n",
    "            print(name, i, param.shape)\n",
    "            print(af.array.save_array(name, af_array, filepath, True))\n",
    "            i = i + 1\n",
    "#af.array.save_array('output', toArrayFire(output), filepath, True)\n",
    "af.array.save_array('output', toArrayFire(output), filepath, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8993,  0.6522,  0.0140, -0.5446, -1.3320,  2.0483,  0.3816,\n",
       "          -1.0369, -1.3780, -0.8465,  0.5010,  0.6418]],\n",
       "\n",
       "        [[-0.0706,  0.8539,  1.7758,  0.7532, -1.3990,  0.7595, -1.7490,\n",
       "          -0.4076,  0.6180,  0.2756, -0.2960, -1.1138]],\n",
       "\n",
       "        [[-0.3730, -0.6208,  2.3744,  1.5793, -0.6512,  0.5313, -0.9931,\n",
       "          -0.0413, -0.4942,  0.2699, -0.9931, -0.5882]],\n",
       "\n",
       "        [[-0.1228, -0.7571,  1.7146,  0.7535, -0.9930,  1.1182, -1.9891,\n",
       "           0.0999,  0.0316, -0.2605,  1.0828, -0.6781]],\n",
       "\n",
       "        [[-0.7519, -0.3129,  1.9925, -0.5571, -2.1034,  1.1056, -0.3702,\n",
       "           0.6410,  0.2674,  0.3839,  0.3998, -0.6947]],\n",
       "\n",
       "        [[-0.4930, -0.1527,  1.9099,  1.5434, -1.8207,  0.9104, -0.7728,\n",
       "           0.3439, -0.7771, -0.1039, -0.1245, -0.4627]],\n",
       "\n",
       "        [[ 0.1966,  0.6162,  1.5532,  0.6287, -1.0405,  1.5832, -1.5561,\n",
       "           0.3241, -1.3947, -0.7082, -0.4102,  0.2077]],\n",
       "\n",
       "        [[-0.0186,  0.0143,  1.4590,  1.9462, -1.8433,  0.5386,  0.0257,\n",
       "          -0.7421,  0.6135, -0.7871, -0.8483, -0.3579]],\n",
       "\n",
       "        [[ 0.1346,  0.5949,  0.5636,  0.7854, -2.0967,  1.1238, -0.8042,\n",
       "          -1.2354,  0.6124, -0.2228,  1.3419, -0.7975]],\n",
       "\n",
       "        [[ 0.5838,  0.0334,  0.0730, -0.1522, -1.4934,  1.8251,  0.3849,\n",
       "          -1.1354, -1.6510, -0.3347,  0.7737,  1.0929]]],\n",
       "       grad_fn=<NativeLayerNormBackward>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
