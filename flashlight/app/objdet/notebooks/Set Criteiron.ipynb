{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arrayfire as af\n",
    "import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toArrayFire(x):\n",
    "    x_np = x.detach().contiguous().numpy()\n",
    "    shape = 1\n",
    "    if len(x_np.shape) == 0:\n",
    "        shape = (1,)\n",
    "    else:\n",
    "        shape = x_np.shape[::-1]\n",
    "    print(shape)\n",
    "    afArray = af.Array(x_np.ctypes.data, shape, x_np.dtype.char)\n",
    "    return afArray\n",
    "\n",
    "def saveStateDict(module, filepath):\n",
    "    i = 0\n",
    "    for (name, param) in module.named_parameters():\n",
    "        #param = module.state_dict()[name]\n",
    "        print(name, \"\\t\", param.size())\n",
    "        if 'in_proj' in name:\n",
    "            print(param.shape)\n",
    "            q, k, v = param.chunk(3, dim=0)\n",
    "            print('in_proj!')\n",
    "            af.array.save_array(name + 'q', toArrayFire(q), filepath, True)\n",
    "            af.array.save_array(name + 'k', toArrayFire(k), filepath, True)\n",
    "            af.array.save_array(name + 'v', toArrayFire(k), filepath, True)\n",
    "            continue\n",
    "        if len(param.size()) > 0:\n",
    "            af_array = toArrayFire(param)\n",
    "            if 'fc' in name and 'weight' in name:\n",
    "                af_array = af.array.transpose(af_array)\n",
    "            af.array.save_array(name, af_array, filepath, True)\n",
    "            i = i + 1\n",
    "    print(i)\n",
    "    for name in module.state_dict():\n",
    "        if 'running' in name:\n",
    "            print(name)\n",
    "            af_array = toArrayFire(module.state_dict()[name])\n",
    "            af.array.save_array(name, af_array, filepath + 'running', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 2)\n",
      "torch.Size([7, 5])\n",
      "weight \t torch.Size([7, 5])\n",
      "(5, 7)\n",
      "1\n",
      "(7, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = '/private/home/padentomasello/scratch/pytorch_testing/basic_linear.array'\n",
    "batchSize = 2\n",
    "inChannels = 5\n",
    "outChannels = 7\n",
    "\n",
    "x = torch.rand(batchSize, inChannels)\n",
    "x_af = toArrayFire(x)\n",
    "\n",
    "af.array.save_array('input', x_af, filepath)\n",
    "model = torch.nn.Linear(inChannels, outChannels, False)\n",
    "weight = torch.stack([torch.arange(0, inChannels, dtype=torch.float32) for i in range(outChannels)], 0)\n",
    "print(weight.shape)\n",
    "model.weight = torch.nn.Parameter(weight)\n",
    "output = model(x)\n",
    "saveStateDict(model, filepath)\n",
    "af.array.save_array('output', toArrayFire(output), filepath, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.2879, 4.2879, 4.2879, 4.2879, 4.2879, 4.2879, 4.2879],\n",
       "        [3.3423, 3.3423, 3.3423, 3.3423, 3.3423, 3.3423, 3.3423]],\n",
       "       grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5, 1)\n",
      "(4, 5, 1)\n",
      "(4, 3)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "from models.detr import *\n",
    "from models.matcher import *\n",
    "class NestedTensor(object):\n",
    "\n",
    "    def __init__(self, mask):\n",
    "        self.mask = mask\n",
    "        self.tensors = torch.ones(1)\n",
    "\n",
    "filepath = '/private/home/padentomasello/scratch/pytorch_testing/matcher.array'\n",
    "\n",
    "matcher = HungarianMatcher(1, 1, 1)\n",
    "batch_size = 1\n",
    "num_queries = 5\n",
    "num_classes = 2\n",
    "\n",
    "pred_logits = torch.rand(batch_size, num_queries, num_classes + 1, requires_grad=True)\n",
    "pred_boxes = torch.rand(batch_size, num_queries, 4, requires_grad=True)\n",
    "outputs = {\n",
    "    \"pred_logits\":pred_logits,\n",
    "    \"pred_boxes\":pred_boxes\n",
    "}\n",
    "\n",
    "targets = [\n",
    "{'boxes': torch.tensor([[0.4395, 0.3252, 0.0628, 0.1583],\n",
    "        [0.4474, 0.3120, 0.3526, 0.4358],\n",
    "        [0.5994, 0.0650, 0.2941, 0.1118]]),\n",
    " 'labels': torch.tensor([32,  1, 85]),\n",
    "},\n",
    " {'boxes': torch.tensor([[0.6240, 0.2875, 0.1698, 0.3400],\n",
    "        [0.2351, 0.5314, 0.4701, 0.9371],\n",
    "        [0.4722, 0.6277, 0.2816, 0.7445],\n",
    "        [0.7453, 0.5528, 0.5094, 0.8945],\n",
    "        [0.6128, 0.6995, 0.1498, 0.0647],\n",
    "        [0.4731, 0.4819, 0.1561, 0.0233],\n",
    "        [0.9721, 0.2031, 0.0187, 0.1447],\n",
    "        [0.9882, 0.1968, 0.0236, 0.1408],\n",
    "        [0.9960, 0.6344, 0.0080, 0.4890],\n",
    "        [0.1050, 0.2647, 0.2100, 0.4400],\n",
    "        [0.9948, 0.4351, 0.0104, 0.0984],\n",
    "        [0.9401, 0.1980, 0.0253, 0.1481]]), \n",
    "  'labels': torch.tensor([ 1,  1,  1,  1, 51, 48, 50, 50, 79,  1, 51, 50])\n",
    " }\n",
    "]\n",
    "targets = [\n",
    "{'boxes': torch.tensor([[0.4395, 0.3252, 0.0628, 0.1583],\n",
    "        [0.4474, 0.3120, 0.3526, 0.4358],\n",
    "        [0.5994, 0.0650, 0.2941, 0.1118]]),\n",
    " 'labels': torch.tensor([0,  1, 1]),}\n",
    "]\n",
    "\n",
    "base_filepath = '/private/home/padentomasello/scratch/pytorch_testing/matcher_test0'\n",
    "bbox_filepath = base_filepath + '_bboxes.array'\n",
    "label_filepath = base_filepath + '_labels.array'\n",
    "af.array.save_array('pred_logits', toArrayFire(pred_logits), base_filepath + 'input.array')\n",
    "af.array.save_array('pred_boxes', toArrayFire(pred_boxes), base_filepath + 'input.array', True)\n",
    "bboxes = [ toArrayFire(target[\"boxes\"]) for target in targets ]\n",
    "labels = [ toArrayFire(target[\"labels\"]) for target in targets ]\n",
    "for box in bboxes:\n",
    "    af.array.save_array('boxes', box, bbox_filepath, True)\n",
    "    \n",
    "for label in labels:\n",
    "    af.array.save_array('label', label, label_filepath, True)\n",
    "\n",
    "\n",
    "result = matcher.forward(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5, 1)\n",
      "0\n",
      "(4, 5, 1)\n",
      "1\n",
      "(4, 3)\n",
      "(3,)\n",
      "here2 0\n",
      "here 0\n",
      "[(tensor([0, 2, 4]), tensor([1, 0, 2]))]\n",
      "here\n",
      "tensor([[1, 2, 0, 2, 1]])\n",
      "tensor([[[0.7941, 0.4272, 0.3814],\n",
      "         [0.3298, 0.4453, 0.9081],\n",
      "         [0.3076, 0.4387, 0.6117],\n",
      "         [0.5073, 0.7663, 0.8768],\n",
      "         [0.3493, 0.3494, 0.5278]]], requires_grad=True)\n",
      "> \u001b[0;32m/private/home/padentomasello/code/detection-transformer/models/detr.py\u001b[0m(116)\u001b[0;36mloss_labels\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    114 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    115 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 116 \u001b[0;31m        \u001b[0mloss_ce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    117 \u001b[0;31m        \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'loss_ce'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss_ce\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    118 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n",
      "{'loss_bbox': tensor(0.7550, grad_fn=<DivBackward0>), 'loss_giou': tensor(1.0904, grad_fn=<DivBackward0>), 'cardinality_error': tensor(2.), 'loss_ce': tensor(1.1906, grad_fn=<NllLoss2DBackward>), 'class_error': tensor(100.)}\n",
      "(1,)\n",
      "loss_bbox 0\n",
      "(1,)\n",
      "loss_giou 1\n",
      "(1,)\n",
      "cardinality_error 2\n",
      "(1,)\n",
      "loss_ce 3\n",
      "(1,)\n",
      "class_error 4\n"
     ]
    }
   ],
   "source": [
    "from models.detr import *\n",
    "base_filepath = '/private/home/padentomasello/scratch/pytorch_testing/set_criterion'\n",
    "bbox_filepath = base_filepath + '_bboxes.array'\n",
    "label_filepath = base_filepath + '_labels.array'\n",
    "loss_filepath = base_filepath + '_loss.array'\n",
    "pred_logits.grad = None\n",
    "pred_boxes.grad = None\n",
    "print(af.array.save_array('pred_logits', toArrayFire(pred_logits), base_filepath + '_input.array', False))\n",
    "print(af.array.save_array('pred_boxes', toArrayFire(pred_boxes), base_filepath + '_input.array', True))\n",
    "bboxes = [ toArrayFire(target[\"boxes\"]) for target in targets ]\n",
    "labels = [ toArrayFire(target[\"labels\"]) for target in targets ]\n",
    "append = False\n",
    "for box in bboxes:\n",
    "    print('here2', af.array.save_array('boxes', box, bbox_filepath, append))\n",
    "    append = True\n",
    "append = False    \n",
    "for label in labels:\n",
    "    print('here', af.array.save_array('label', label, label_filepath, append))\n",
    "    append = True\n",
    "\n",
    "\n",
    "result = matcher.forward(outputs, targets)\n",
    "weight_dict = {'loss_ce': 1, 'loss_bbox': 1}\n",
    "weight_dict['loss_giou'] = 1\n",
    "losses = []\n",
    "losses.extend(['boxes', 'cardinality'])\n",
    "losses.append('labels')\n",
    "eos_coef = 0.1\n",
    "crit = SetCriterion(num_classes, matcher, weight_dict, eos_coef, losses)\n",
    "append = False\n",
    "losses = crit.forward(outputs, targets)\n",
    "for key, array in losses.items():\n",
    "    print(key, af.array.save_array(key + '_0', toArrayFire(array), loss_filepath, append))\n",
    "    #array.backward(retain_graph=True)\n",
    "    append = True\n",
    "losses['loss_bbox'].backward(retain_graph=True)\n",
    "losses['loss_giou'].backward(retain_graph=True)\n",
    "losses['loss_ce'].backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.0217,  0.8772,  0.0910,  0.2760],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.3333, -1.9450,  0.3566, -0.5736],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.3333,  0.3333, -1.3966,  0.4582]]])\n",
      "tensor([[[ 0.1327, -0.2205,  0.0878],\n",
      "         [ 0.0080,  0.0090, -0.0170],\n",
      "         [-0.2231,  0.1019,  0.1212],\n",
      "         [ 0.0083,  0.0108, -0.0192],\n",
      "         [ 0.0978, -0.2147,  0.1169]]])\n"
     ]
    }
   ],
   "source": [
    "print(outputs[\"pred_boxes\"].grad)\n",
    "print(outputs[\"pred_logits\"].grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/private/home/padentomasello/scratch/pytorch_testing/set_criterion_loss.array'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "(2,)\n",
      "(3,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.7808, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = '/private/home/padentomasello/scratch/pytorch_testing/weight_cross_entropy.array'\n",
    "\n",
    "num_classes = 2\n",
    "weights = torch.ones(num_classes)\n",
    "weights[0:1] = 0.1\n",
    "input = torch.randn(3, num_classes, requires_grad=True)\n",
    "target = torch.randint(num_classes, (3,), dtype=torch.int64)\n",
    "af.array.save_array('input', toArrayFire(input), filepath, False)\n",
    "af.array.save_array('weight', toArrayFire(weights), filepath, True)\n",
    "af.array.save_array('target', toArrayFire(target), filepath, True)\n",
    "F.cross_entropy(input, target, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmaxed = torch.nn.functional.log_softmax(input, 1)\n",
    "loss = torch.nn.functional.nll_loss(softmaxed, target, weights, None, -1, None, 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0511,  0.0511],\n",
       "        [ 0.7241, -0.7241],\n",
       "        [-0.0077,  0.0077]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9484, -0.4900],\n",
       "        [-0.1404, -2.0324],\n",
       "        [-0.0971, -2.3803]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmaxed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0948, 2.0324, 0.0097], grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.nll_loss(softmaxed, target, weights, None, -1, None, 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7808, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.nll_loss(softmaxed, target, weights, None, -1, None, 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.1369, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.nll_loss(softmaxed, target, weights, None, -1, None, 'sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9484, 2.0324, 0.0971], grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.nll_loss(softmaxed, target, None, None, -1, None, 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.0779, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.nll_loss(softmaxed, target, None, None, -1, None, 'sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0260, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.nll_loss(softmaxed, target, None, None, -1, None, 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
